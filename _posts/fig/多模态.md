# 多模态

- 多模态

  - 信息表示模式
    - 图片
    - 文本
    - 视频
    - 音频
  - 不同模态有不通特点

- 对齐

  - align 
  - 表征学习：多个模态都有其表征，相同表征尽可能接近

- 迁移学习

  - 有已训练的模型，
  - 新的任务上，新的数据集上，微调
    - 更小的学习率
    - 使用更少的优化参数
  - 大模型
    - 迁移数据量不够
    - 计算资源不够

- zero shot：

  - 在大数据集上训练的模型融合不通类型的特征
  - 给予一些描述，不再任何数据集上训练
    - 很像马
    - 身上有条纹
    - 黑白相间
    -  ====== > 推理为 斑马

- **clip** （图文匹配）4亿个图片文本对

  - 表征学习

    - bert   => 文本   
    - vit      => 图像

  - 一个批次 30000 个图文对，生成 30000 个图片向量，30000个文本向量 （768）

    - 对应的图文对应该相似度大
    - 不对应的图片相似度小

  - 弱对齐

    - 文本和图像对是弱对齐的，没有人为标注
    - 不同的文本之间是有相似性的

  - 推理阶段

    - 一张图片 => 图像特征
    - 有多种类别（这是一个...） => n 个文本特征
    - 求相似度 => 向量相乘

    （图片和文本反过来也一样）

    （甚至能做文本和文本的匹配，图片和图片的匹配）

- BLIP

  ![image-20231104220707159](/Users/asic-mbp/Library/Application Support/typora-user-images/image-20231104220707159.png)

  - 自然语言理解  + 自然语言生成任务  =》 多模态通用模型

  - 三塔模型

    - 对比学习 =〉ITC 
    - 分类任务 =》ITM  二分类任务
      - 负样本构建（ITC 中难以区分的样本）
    - 生成任务 =〉LM 重新预测文本

  - 解决弱监督图文数据清洗问题

    ![image-20231104221250394](/Users/asic-mbp/Library/Application Support/typora-user-images/image-20231104221250394.png)

- - 网上爬下来的数据（弱匹配）
  - 人工标注的（较为准确的）
  - 生成的 



- BLIP2





1. 第二个点的研究，想法：是将图像样例转变为文本样例的目标计数方法的研究
2. 其中涉及到了多模态的问题
   1. 现在在看 clip
   2. blip 大模型，想要借鉴其思想
3. 可能存在的问题
   1. 数据量不够大
   2. 





**注意力机制**

1. bi self-attention
2. cross attention
3. causal self-attention





### AVL 树

- 节点
- 插入
- 查找
- 删除
- 树高
- 平衡因子
- 左旋
- 右旋